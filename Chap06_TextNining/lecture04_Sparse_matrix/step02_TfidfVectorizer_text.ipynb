{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sparse matrix 작업 절차 \n",
    " 1. csv file load\n",
    " 2. texts(x), target(y) 전처리 \n",
    " 3. max features \n",
    " 4. sparse matrix\n",
    "\"\"\"\n",
    "\n",
    "import string # text 전처리 \n",
    "# sparse matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "import pandas as pd # csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       5 non-null      object\n",
      " 1   1       5 non-null      object\n",
      "dtypes: object(2)\n",
      "memory usage: 208.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# 1. csv file load\n",
    "spam_data = pd.read_csv(\"C:/Users/hyebin/Desktop/study/python_ML/data/textMining_data/temp_spam_data.csv\",\n",
    "            header = None, encoding='utf-8')\n",
    "spam_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     ham\n",
      "1    spam\n",
      "2     ham\n",
      "3    spam\n",
      "4     ham\n",
      "Name: 0, dtype: object\n",
      "0      우리나라    대한민국, 우리나라 만세\n",
      "1        비아그라 500GRAM 정력 최고!\n",
      "2                 나는 대한민국 사람\n",
      "3    보험료 15000원에 평생 보장 마감 임박\n",
      "4                     나는 홍길동\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 2. texts(x), target(y) 전처리 \n",
    "target = spam_data[0] # 1번칼럼 \n",
    "texts = spam_data[1] # 2번칼럼 \n",
    "\n",
    "print(target)\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) target -> dummy 생성 \n",
    "target = [1 if t == 'spam' else 0 for t in target]\n",
    "target # [0, 1, 0, 1, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['우리나라 대한민국 우리나라 만세', '비아그라 gram 정력 최고', '나는 대한민국 사람', '보험료 원에 평생 보장 마감 임박', '나는 홍길동']\n"
     ]
    }
   ],
   "source": [
    "# 2) texts 전처리 : 숫자, 특수문자, 공백 제거 \n",
    "def text_prepro(texts):\n",
    "    # Lower case\n",
    "    texts = [x.lower() for x in texts]\n",
    "    # Remove punctuation\n",
    "    texts = [''.join(c for c in x if c not in string.punctuation) for x in texts]\n",
    "    # Remove numbers\n",
    "    texts = [''.join(c for c in x if c not in string.digits) for x in texts]\n",
    "    # Trim extra whitespace\n",
    "    texts = [' '.join(x.split()) for x in texts]\n",
    "    return texts\n",
    "# 함수 호출 : texts 전처리 \n",
    "texts = text_prepro(texts)   \n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'우리나라': 9, '대한민국': 2, '만세': 4, '비아그라': 7, 'gram': 0, '정력': 12, '최고': 13, '나는': 1, '사람': 8, '보험료': 6, '원에': 10, '평생': 14, '보장': 5, '마감': 3, '임박': 11, '홍길동': 15}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. max features \n",
    "'''\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_fit = tfidf.fit(texts) # texts -> words \n",
    "'''\n",
    "tfidf_fit = TfidfVectorizer().fit(texts)\n",
    "voc = tfidf_fit.vocabulary_ # 단어 반환 \n",
    "print(voc)\n",
    "len(voc) # 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmax_features = len(voc)  : 전체 단어를 max_features\\nmax_features = n : 전체 단어 중에서 n개 단어 사용 \\n차원수(열수)를 결정하는 변수 \\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = len(voc) # 16\n",
    "#max_features = 8  \n",
    "'''\n",
    "max_features = len(voc)  : 전체 단어를 max_features\n",
    "max_features = n : 전체 단어 중에서 n개 단어 사용 \n",
    "차원수(열수)를 결정하는 변수 \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4)\t0.4206690600631704\n",
      "  (0, 2)\t0.3393931489111758\n",
      "  (0, 9)\t0.8413381201263408\n",
      "  (1, 13)\t0.5\n",
      "  (1, 12)\t0.5\n",
      "  (1, 0)\t0.5\n",
      "  (1, 7)\t0.5\n",
      "  (2, 8)\t0.6591180018251055\n",
      "  (2, 1)\t0.5317722537280788\n",
      "  (2, 2)\t0.5317722537280788\n",
      "  (3, 11)\t0.40824829046386296\n",
      "  (3, 3)\t0.40824829046386296\n",
      "  (3, 5)\t0.40824829046386296\n",
      "  (3, 14)\t0.40824829046386296\n",
      "  (3, 10)\t0.40824829046386296\n",
      "  (3, 6)\t0.40824829046386296\n",
      "  (4, 15)\t0.7782829228046183\n",
      "  (4, 1)\t0.6279137616509933\n"
     ]
    }
   ],
   "source": [
    "# 4. sparse matrix\n",
    "tfidf = TfidfVectorizer(max_features=max_features, stop_words='english')\n",
    "sparse_mat = tfidf.fit_transform(texts) # stances -> sparse matrix\n",
    "print(sparse_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.33939315 0.         0.42066906 0.\n",
      "  0.         0.         0.         0.84133812 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.5        0.         0.         0.         0.         0.\n",
      "  0.         0.5        0.         0.         0.         0.\n",
      "  0.5        0.5        0.         0.        ]\n",
      " [0.         0.53177225 0.53177225 0.         0.         0.\n",
      "  0.         0.         0.659118   0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.40824829 0.         0.40824829\n",
      "  0.40824829 0.         0.         0.         0.40824829 0.40824829\n",
      "  0.         0.         0.40824829 0.        ]\n",
      " [0.         0.62791376 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.77828292]]\n"
     ]
    }
   ],
   "source": [
    "arr_sparse_mat = sparse_mat.toarray()\n",
    "print(arr_sparse_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
